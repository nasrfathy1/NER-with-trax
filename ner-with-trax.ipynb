{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install trax\nimport numpy as np\nimport pandas as pd\nfrom trax import layers as tl\nfrom nltk.tokenize import word_tokenize\nfrom trax.fastmath import numpy as np\nimport random as rnd\nfrom trax.supervised.training import TrainTask,EvalTask,Loop\nimport trax","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-05T14:24:14.111028Z","iopub.execute_input":"2023-05-05T14:24:14.111399Z","iopub.status.idle":"2023-05-05T14:26:00.811729Z","shell.execute_reply.started":"2023-05-05T14:24:14.111370Z","shell.execute_reply":"2023-05-05T14:26:00.810621Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting trax\n  Downloading trax-1.4.1-py2.py3-none-any.whl (637 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.9/637.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from trax) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from trax) (1.23.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from trax) (3.6.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from trax) (1.16.0)\nRequirement already satisfied: tensorflow-text in /opt/conda/lib/python3.10/site-packages (from trax) (2.11.0)\nCollecting funcsigs\n  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\nCollecting gin-config\n  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: jax in /opt/conda/lib/python3.10/site-packages (from trax) (0.4.8)\nRequirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (from trax) (4.9.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from trax) (5.9.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from trax) (1.9.3)\nRequirement already satisfied: gym in /opt/conda/lib/python3.10/site-packages (from trax) (0.26.2)\nRequirement already satisfied: jaxlib in /opt/conda/lib/python3.10/site-packages (from trax) (0.4.7)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym->trax) (0.0.8)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym->trax) (2.2.1)\nRequirement already satisfied: ml-dtypes>=0.0.3 in /opt/conda/lib/python3.10/site-packages (from jax->trax) (0.1.0)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax->trax) (3.3.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (1.4.4)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (4.39.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (9.5.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (0.11.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (1.0.7)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (2.8.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->trax) (3.0.9)\nRequirement already satisfied: etils[enp,epath]>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (1.2.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (2.28.2)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (1.15.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (3.20.3)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (2.3)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (0.10.2)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (8.1.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (4.64.1)\nRequirement already satisfied: array-record in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (0.2.0)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (0.14.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (2.2.0)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->trax) (0.1.8)\nRequirement already satisfied: tensorflow<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text->trax) (2.11.0)\nRequirement already satisfied: tensorflow-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text->trax) (0.12.0)\nRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->trax) (5.12.0)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->trax) (3.15.0)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->trax) (4.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->trax) (1.26.15)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (16.0.0)\nCollecting protobuf\n  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.6.3)\nRequirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.11.2)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.2.0)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (23.3.3)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (3.8.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.53.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.29.0)\nRequirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.11.0)\nRequirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.11.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (59.8.0)\nRequirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow-datasets->trax) (1.59.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.40.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (3.4.3)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.8.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.17.2)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.4.6)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.2.3)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.6.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (5.3.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (3.2.2)\nInstalling collected packages: gin-config, funcsigs, protobuf, trax\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nonnx 1.13.1 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nkfp 1.8.20 requires google-api-python-client<2,>=1.7.8, but you have google-api-python-client 2.86.0 which is incompatible.\nkfp 1.8.20 requires PyYAML<6,>=5.3, but you have pyyaml 6.0 which is incompatible.\ngcsfs 2023.3.0 requires fsspec==2023.3.0, but you have fsspec 2023.4.0 which is incompatible.\nbeatrix-jupyterlab 2023.46.184821 requires jupyter-server~=1.16, but you have jupyter-server 2.5.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed funcsigs-1.0.2 gin-config-0.5.0 protobuf-3.19.6 trax-1.4.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(r'/kaggle/input/ner-dataset/ner_datasetreference.csv',encoding = \"ISO-8859-1\")","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:26:00.813871Z","iopub.execute_input":"2023-05-05T14:26:00.814991Z","iopub.status.idle":"2023-05-05T14:26:01.746980Z","shell.execute_reply.started":"2023-05-05T14:26:00.814929Z","shell.execute_reply":"2023-05-05T14:26:01.746172Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:26:01.752869Z","iopub.execute_input":"2023-05-05T14:26:01.753216Z","iopub.status.idle":"2023-05-05T14:26:01.782635Z","shell.execute_reply.started":"2023-05-05T14:26:01.753185Z","shell.execute_reply":"2023-05-05T14:26:01.781426Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"    Sentence #           Word  POS    Tag\n0  Sentence: 1      Thousands  NNS      O\n1          NaN             of   IN      O\n2          NaN  demonstrators  NNS      O\n3          NaN           have  VBP      O\n4          NaN        marched  VBN      O\n5          NaN        through   IN      O\n6          NaN         London  NNP  B-geo\n7          NaN             to   TO      O\n8          NaN        protest   VB      O\n9          NaN            the   DT      O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>Thousands</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>demonstrators</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>marched</td>\n      <td>VBN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>through</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>London</td>\n      <td>NNP</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>protest</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"index=data.dropna().index\nindex","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:26:01.784560Z","iopub.execute_input":"2023-05-05T14:26:01.785009Z","iopub.status.idle":"2023-05-05T14:26:02.444355Z","shell.execute_reply.started":"2023-05-05T14:26:01.784946Z","shell.execute_reply":"2023-05-05T14:26:02.442942Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Int64Index([      0,      24,      54,      68,      83,     108,     132,\n                153,     181,     196,\n            ...\n            1048375, 1048400, 1048422, 1048438, 1048472, 1048501, 1048521,\n            1048545, 1048556, 1048567],\n           dtype='int64', length=47959)"},"metadata":{}}]},{"cell_type":"code","source":"sentence=[]\ntag=[]\nfor idx,i in enumerate(index):\n    one_Sentence=''\n    one_tag=''\n    if i ==index[-1]:\n        break\n    for i in range(index[idx],index[idx+1]):\n        one_Sentence+=' '+data.iloc[i]['Word']\n        one_tag+=' '+data.iloc[i]['Tag']\n    sentence.append(one_Sentence)\n    tag.append(one_tag)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:26:02.446369Z","iopub.execute_input":"2023-05-05T14:26:02.446880Z","iopub.status.idle":"2023-05-05T14:27:25.179390Z","shell.execute_reply.started":"2023-05-05T14:26:02.446838Z","shell.execute_reply":"2023-05-05T14:27:25.178530Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(sentence[3])\nprint(tag[3])\ndata.iloc[index[3]:index[4]]","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:27:25.180570Z","iopub.execute_input":"2023-05-05T14:27:25.181408Z","iopub.status.idle":"2023-05-05T14:27:25.195741Z","shell.execute_reply.started":"2023-05-05T14:27:25.181373Z","shell.execute_reply":"2023-05-05T14:27:25.194602Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":" Police put the number of marchers at 10,000 while organizers claimed it was 1,00,000 .\n O O O O O O O O O O O O O O O\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     Sentence #        Word  POS Tag\n68  Sentence: 4      Police  NNS   O\n69          NaN         put  VBD   O\n70          NaN         the   DT   O\n71          NaN      number   NN   O\n72          NaN          of   IN   O\n73          NaN    marchers  NNS   O\n74          NaN          at   IN   O\n75          NaN      10,000   CD   O\n76          NaN       while   IN   O\n77          NaN  organizers  NNS   O\n78          NaN     claimed  VBD   O\n79          NaN          it  PRP   O\n80          NaN         was  VBD   O\n81          NaN    1,00,000   CD   O\n82          NaN           .    .   O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>68</th>\n      <td>Sentence: 4</td>\n      <td>Police</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>NaN</td>\n      <td>put</td>\n      <td>VBD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>NaN</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>NaN</td>\n      <td>number</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>NaN</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>NaN</td>\n      <td>marchers</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>NaN</td>\n      <td>at</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>NaN</td>\n      <td>10,000</td>\n      <td>CD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>NaN</td>\n      <td>while</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>NaN</td>\n      <td>organizers</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>NaN</td>\n      <td>claimed</td>\n      <td>VBD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>NaN</td>\n      <td>it</td>\n      <td>PRP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>NaN</td>\n      <td>was</td>\n      <td>VBD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>NaN</td>\n      <td>1,00,000</td>\n      <td>CD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>NaN</td>\n      <td>.</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print('data size=',len(sentence))\ndata_size=len(sentence)\ntrain_data=sentence[:int(data_size*.8)]\ntest_data=sentence[len(train_data):int(data_size*.9)]\nval_data=sentence[int(data_size*.9):]\ntrain_label=tag[:int(data_size*.8)]\ntest_label=tag[len(train_data):int(data_size*.9)]\nval_label=tag[int(data_size*.9):]\nprint(len(train_data),len(test_data),len(val_data))\nprint(len(train_label),len(test_label),len(val_label))\nprint(train_data[0])\nprint(train_label[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:27:25.198073Z","iopub.execute_input":"2023-05-05T14:27:25.198999Z","iopub.status.idle":"2023-05-05T14:27:25.216128Z","shell.execute_reply.started":"2023-05-05T14:27:25.198929Z","shell.execute_reply":"2023-05-05T14:27:25.214860Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"data size= 47958\n38366 4796 4796\n38366 4796 4796\n Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n","output_type":"stream"}]},{"cell_type":"code","source":"def word_to_number (data):\n    vocab={'<pad>':0,'<unKnow>':1}\n    for i in data:\n        words=word_tokenize(i)\n        for word in words:\n            if word not in list(vocab):\n                vocab[word]=len(vocab)\n    return vocab\n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:07:39.384963Z","iopub.execute_input":"2023-05-05T18:07:39.387231Z","iopub.status.idle":"2023-05-05T18:07:39.399924Z","shell.execute_reply.started":"2023-05-05T18:07:39.387136Z","shell.execute_reply":"2023-05-05T18:07:39.398178Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"vocab_word=word_to_number(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:07:40.517456Z","iopub.execute_input":"2023-05-05T18:07:40.517872Z","iopub.status.idle":"2023-05-05T18:14:16.633917Z","shell.execute_reply.started":"2023-05-05T18:07:40.517837Z","shell.execute_reply":"2023-05-05T18:14:16.632394Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"code","source":"vocab_word['<pad>']","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:14:16.636737Z","iopub.execute_input":"2023-05-05T18:14:16.637489Z","iopub.status.idle":"2023-05-05T18:14:16.646625Z","shell.execute_reply.started":"2023-05-05T18:14:16.637437Z","shell.execute_reply":"2023-05-05T18:14:16.645244Z"},"trusted":true},"execution_count":184,"outputs":[{"execution_count":184,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"def tags_to_number (label):\n    vocab_tags={\"<pad>\":0}\n    number_to_tags={0:'<pad>'}\n    for tags in label:\n        tags=tags.split()\n        for tag in tags:\n            if tag not in list(vocab_tags):\n                vocab_tags[tag]=len(vocab_tags)\n                number_to_tags[len(number_to_tags)]=tag\n    return vocab_tags,number_to_tags\n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T21:18:10.273727Z","iopub.execute_input":"2023-05-05T21:18:10.274643Z","iopub.status.idle":"2023-05-05T21:18:10.280507Z","shell.execute_reply.started":"2023-05-05T21:18:10.274600Z","shell.execute_reply":"2023-05-05T21:18:10.279312Z"},"trusted":true},"execution_count":287,"outputs":[]},{"cell_type":"code","source":"vocab_tags,number_to_tags=tags_to_number(train_label)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T21:18:10.560680Z","iopub.execute_input":"2023-05-05T21:18:10.561058Z","iopub.status.idle":"2023-05-05T21:18:11.077638Z","shell.execute_reply.started":"2023-05-05T21:18:10.561030Z","shell.execute_reply":"2023-05-05T21:18:11.076461Z"},"trusted":true},"execution_count":288,"outputs":[]},{"cell_type":"code","source":"number_to_tags","metadata":{"execution":{"iopub.status.busy":"2023-05-05T21:18:11.079364Z","iopub.execute_input":"2023-05-05T21:18:11.079719Z","iopub.status.idle":"2023-05-05T21:18:11.086497Z","shell.execute_reply.started":"2023-05-05T21:18:11.079681Z","shell.execute_reply":"2023-05-05T21:18:11.085483Z"},"trusted":true},"execution_count":289,"outputs":[{"execution_count":289,"output_type":"execute_result","data":{"text/plain":"{0: '<pad>',\n 1: 'O',\n 2: 'B-geo',\n 3: 'B-gpe',\n 4: 'B-per',\n 5: 'I-geo',\n 6: 'B-org',\n 7: 'I-org',\n 8: 'B-tim',\n 9: 'B-art',\n 10: 'I-art',\n 11: 'I-per',\n 12: 'I-gpe',\n 13: 'I-tim',\n 14: 'B-nat',\n 15: 'B-eve',\n 16: 'I-eve',\n 17: 'I-nat'}"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_sentence(sentence,vocab):\n    tokenize_sentence=[]\n    words=word_tokenize(sentence)\n    for word in words:\n        \n        tokenize_sentence.append(vocab.get(word,1))\n    return tokenize_sentence\n        ","metadata":{"execution":{"iopub.status.busy":"2023-05-05T21:14:12.738458Z","iopub.execute_input":"2023-05-05T21:14:12.738916Z","iopub.status.idle":"2023-05-05T21:14:12.744638Z","shell.execute_reply.started":"2023-05-05T21:14:12.738863Z","shell.execute_reply":"2023-05-05T21:14:12.743918Z"},"trusted":true},"execution_count":260,"outputs":[]},{"cell_type":"code","source":"def gnerator_data(data,label):\n    data_size=len(data)\n    index=[*range(data_size)]\n    idx=0\n    while True:\n        if idx>=data_size:\n            idx=0\n        rnd.shuffle(index)\n        sentence=tokenize_sentence(data[index[idx]],vocab_word)\n        tags=tokenize_sentence(label[index[idx]],vocab_tags)\n        idx+=1\n        X=np.array(sentence)\n        Y=np.array(tags)\n        yield ((X,Y))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:14:17.203387Z","iopub.execute_input":"2023-05-05T18:14:17.203893Z","iopub.status.idle":"2023-05-05T18:14:17.214639Z","shell.execute_reply.started":"2023-05-05T18:14:17.203840Z","shell.execute_reply":"2023-05-05T18:14:17.213437Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"def gnerator_test_data(data,label):\n    data_size=len(data)\n    index=[*range(data_size)]\n    X=[]\n    Y=[]\n    while True:\n        for i in index:\n            sentence=tokenize_sentence(data[index[idx]],vocab_word)\n            tags=tokenize_sentence(label[index[idx]],vocab_tags)\n            Y.append(tags)\n            X.append(sentence)\n        X=np.array(X)\n        Y=np.array(Y)\n        yield ((X,Y))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T20:48:43.313028Z","iopub.execute_input":"2023-05-05T20:48:43.313481Z","iopub.status.idle":"2023-05-05T20:48:43.321305Z","shell.execute_reply.started":"2023-05-05T20:48:43.313445Z","shell.execute_reply":"2023-05-05T20:48:43.320303Z"},"trusted":true},"execution_count":208,"outputs":[]},{"cell_type":"code","source":"X,Y=next(gnerator_data(train_data,train_label))\nX.shape,Y.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:14:17.216376Z","iopub.execute_input":"2023-05-05T18:14:17.216835Z","iopub.status.idle":"2023-05-05T18:14:17.265319Z","shell.execute_reply.started":"2023-05-05T18:14:17.216790Z","shell.execute_reply":"2023-05-05T18:14:17.264315Z"},"trusted":true},"execution_count":190,"outputs":[{"execution_count":190,"output_type":"execute_result","data":{"text/plain":"((12,), (12,))"},"metadata":{}}]},{"cell_type":"code","source":"boundaries =  [8,   16,  32, 64, 128, 256, 512]\nbatch_sizes = [256,128, 64, 32, 16,    8,   4,  2]\n\n\n# Create the generators.\ntrain_batch_stream = trax.data.BucketByLength(\n    boundaries, batch_sizes,\n    length_keys=[0, 1]  # As before: count inputs and targets to length.\n)(gnerator_data(train_data,train_label))\n\nval_batch_stream = trax.data.BucketByLength(\n    boundaries, batch_sizes,\n    length_keys=[0, 1]  # As before: count inputs and targets to length.\n)(gnerator_data(val_data,val_label))\n\n\ntest_batch_stream = trax.data.BucketByLength(\n    boundaries, batch_sizes,\n    length_keys=[0, 1]  # As before: count inputs and targets to length.\n)(gnerator_data(test_data,test_label))\n\ntrain_batch_stream = trax.data.AddLossWeights(id_to_mask=vocab_word['<pad>'])(train_batch_stream)\nval_batch_stream = trax.data.AddLossWeights(id_to_mask=vocab_word['<pad>'])(val_batch_stream)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:14:17.266620Z","iopub.execute_input":"2023-05-05T18:14:17.266936Z","iopub.status.idle":"2023-05-05T18:14:17.283734Z","shell.execute_reply.started":"2023-05-05T18:14:17.266907Z","shell.execute_reply":"2023-05-05T18:14:17.282323Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"X,Y,M=next(train_batch_stream)\nX.shape,Y.shape,M.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:14:17.288988Z","iopub.execute_input":"2023-05-05T18:14:17.289482Z","iopub.status.idle":"2023-05-05T18:14:20.199621Z","shell.execute_reply.started":"2023-05-05T18:14:17.289442Z","shell.execute_reply":"2023-05-05T18:14:20.198747Z"},"trusted":true},"execution_count":192,"outputs":[{"execution_count":192,"output_type":"execute_result","data":{"text/plain":"((64, 32), (64, 32), (64, 32))"},"metadata":{}}]},{"cell_type":"code","source":"X[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:14:20.200940Z","iopub.execute_input":"2023-05-05T18:14:20.201797Z","iopub.status.idle":"2023-05-05T18:14:20.208271Z","shell.execute_reply.started":"2023-05-05T18:14:20.201761Z","shell.execute_reply":"2023-05-05T18:14:20.207016Z"},"trusted":true},"execution_count":193,"outputs":[{"execution_count":193,"output_type":"execute_result","data":{"text/plain":"array([7710,  287,  174,   11, 1815,   70, 7711, 2922,   61, 5231,  193,\n       7712,   47,  265,  282, 1317,   23,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n      dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"Y[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:14:20.209457Z","iopub.execute_input":"2023-05-05T18:14:20.209771Z","iopub.status.idle":"2023-05-05T18:14:20.221507Z","shell.execute_reply.started":"2023-05-05T18:14:20.209743Z","shell.execute_reply":"2023-05-05T18:14:20.220640Z"},"trusted":true},"execution_count":194,"outputs":[{"execution_count":194,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"M[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:14:20.222590Z","iopub.execute_input":"2023-05-05T18:14:20.223575Z","iopub.status.idle":"2023-05-05T18:14:20.234418Z","shell.execute_reply.started":"2023-05-05T18:14:20.223538Z","shell.execute_reply":"2023-05-05T18:14:20.233614Z"},"trusted":true},"execution_count":195,"outputs":[{"execution_count":195,"output_type":"execute_result","data":{"text/plain":"array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"def Model(d_model,n_layer):\n    model=tl.Serial([tl.Embedding(len(vocab_word),d_model),\n                         [tl.LSTM(d_model) for _ in range(n_layer)],\n                          tl.Dense(len(vocab_tags)),\n                          tl.LogSoftmax()\n\n    ])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:14:20.235435Z","iopub.execute_input":"2023-05-05T18:14:20.236464Z","iopub.status.idle":"2023-05-05T18:14:20.245041Z","shell.execute_reply.started":"2023-05-05T18:14:20.236426Z","shell.execute_reply":"2023-05-05T18:14:20.243917Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"def train_model(train_batch_stream,val_batch_stream,n_steps,model,output_dir='./model'):\n    train_task=TrainTask(train_batch_stream,\n                         loss_layer=tl.CrossEntropyLoss(),\n                         optimizer=trax.optimizers.Adam(0.001),\n                         n_steps_per_checkpoint=100)\n    \n    eval_task=EvalTask(val_batch_stream,\n                        metrics=[tl.CrossEntropyLoss(),tl.Accuracy()],\n                      )\n    \n    training_loop =Loop(\n        model, # A model to train\n        train_task, # A train task\n        eval_tasks = [eval_task], # The evaluation task\n        output_dir = output_dir # The output directory\n    )\n\n    # Train with train_steps\n    training_loop.run(n_steps = n_steps)\n### END CODE HERE ###\n    return training_loop\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:14:20.246692Z","iopub.execute_input":"2023-05-05T18:14:20.247781Z","iopub.status.idle":"2023-05-05T18:14:20.258148Z","shell.execute_reply.started":"2023-05-05T18:14:20.247739Z","shell.execute_reply":"2023-05-05T18:14:20.256859Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"model=Model(512,3)\nn_steps=int((len(train_data)/64))*3\nprint(n_steps)\n\ntraining=train_model(train_batch_stream,val_batch_stream,n_steps,model,output_dir='./model')","metadata":{"execution":{"iopub.status.busy":"2023-05-05T18:29:46.517967Z","iopub.execute_input":"2023-05-05T18:29:46.518674Z","iopub.status.idle":"2023-05-05T20:34:28.272896Z","shell.execute_reply.started":"2023-05-05T18:29:46.518632Z","shell.execute_reply":"2023-05-05T20:34:28.271389Z"},"trusted":true},"execution_count":200,"outputs":[{"name":"stdout","text":"1797\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trax/layers/base.py:851: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n  with gzip.GzipFile(fileobj=f, compresslevel=compresslevel) as gzipf:\n","output_type":"stream"},{"name":"stdout","text":"\nStep      1: Total number of trainable weights: 22593554\nStep      1: Ran 1 train steps in 17.03 secs\nStep      1: train CrossEntropyLoss |  2.75794077\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trax/supervised/training.py:1249: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n  with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:\n","output_type":"stream"},{"name":"stdout","text":"Step      1: eval  CrossEntropyLoss |  1.21168351\nStep      1: eval          Accuracy |  0.82526177\n\nStep    100: Ran 99 train steps in 423.11 secs\nStep    100: train CrossEntropyLoss |  0.77143353\nStep    100: eval  CrossEntropyLoss |  0.78344017\nStep    100: eval          Accuracy |  0.83703703\n\nStep    200: Ran 100 train steps in 420.96 secs\nStep    200: train CrossEntropyLoss |  0.75090826\nStep    200: eval  CrossEntropyLoss |  0.83843350\nStep    200: eval          Accuracy |  0.82199830\n\nStep    300: Ran 100 train steps in 425.85 secs\nStep    300: train CrossEntropyLoss |  0.72933584\nStep    300: eval  CrossEntropyLoss |  0.70461553\nStep    300: eval          Accuracy |  0.85246950\n\nStep    400: Ran 100 train steps in 424.21 secs\nStep    400: train CrossEntropyLoss |  0.71576393\nStep    400: eval  CrossEntropyLoss |  0.62360048\nStep    400: eval          Accuracy |  0.87216735\n\nStep    500: Ran 100 train steps in 420.69 secs\nStep    500: train CrossEntropyLoss |  0.70304674\nStep    500: eval  CrossEntropyLoss |  0.69502372\nStep    500: eval          Accuracy |  0.84393442\n\nStep    600: Ran 100 train steps in 427.61 secs\nStep    600: train CrossEntropyLoss |  0.43959194\nStep    600: eval  CrossEntropyLoss |  0.35791335\nStep    600: eval          Accuracy |  0.89986908\n\nStep    700: Ran 100 train steps in 430.67 secs\nStep    700: train CrossEntropyLoss |  0.30986291\nStep    700: eval  CrossEntropyLoss |  0.33080161\nStep    700: eval          Accuracy |  0.89673436\n\nStep    800: Ran 100 train steps in 419.02 secs\nStep    800: train CrossEntropyLoss |  0.24746284\nStep    800: eval  CrossEntropyLoss |  0.22023220\nStep    800: eval          Accuracy |  0.93678546\n\nStep    900: Ran 100 train steps in 421.01 secs\nStep    900: train CrossEntropyLoss |  0.20726019\nStep    900: eval  CrossEntropyLoss |  0.18497872\nStep    900: eval          Accuracy |  0.95123583\n\nStep   1000: Ran 100 train steps in 421.10 secs\nStep   1000: train CrossEntropyLoss |  0.18199019\nStep   1000: eval  CrossEntropyLoss |  0.19112380\nStep   1000: eval          Accuracy |  0.94768614\n\nStep   1100: Ran 100 train steps in 434.91 secs\nStep   1100: train CrossEntropyLoss |  0.16313289\nStep   1100: eval  CrossEntropyLoss |  0.17042027\nStep   1100: eval          Accuracy |  0.94836956\n\nStep   1200: Ran 100 train steps in 422.01 secs\nStep   1200: train CrossEntropyLoss |  0.14421315\nStep   1200: eval  CrossEntropyLoss |  0.28379482\nStep   1200: eval          Accuracy |  0.92479336\n\nStep   1300: Ran 100 train steps in 422.14 secs\nStep   1300: train CrossEntropyLoss |  0.13850474\nStep   1300: eval  CrossEntropyLoss |  0.12661833\nStep   1300: eval          Accuracy |  0.95742095\n\nStep   1400: Ran 100 train steps in 403.97 secs\nStep   1400: train CrossEntropyLoss |  0.13069808\nStep   1400: eval  CrossEntropyLoss |  0.15500197\nStep   1400: eval          Accuracy |  0.95863909\n\nStep   1500: Ran 100 train steps in 397.06 secs\nStep   1500: train CrossEntropyLoss |  0.12419637\nStep   1500: eval  CrossEntropyLoss |  0.13482124\nStep   1500: eval          Accuracy |  0.96038252\n\nStep   1600: Ran 100 train steps in 389.26 secs\nStep   1600: train CrossEntropyLoss |  0.12444929\nStep   1600: eval  CrossEntropyLoss |  0.13830192\nStep   1600: eval          Accuracy |  0.95328367\n\nStep   1700: Ran 100 train steps in 390.10 secs\nStep   1700: train CrossEntropyLoss |  0.11889290\nStep   1700: eval  CrossEntropyLoss |  0.20363174\nStep   1700: eval          Accuracy |  0.94430053\n","output_type":"stream"}]},{"cell_type":"code","source":"boundaries =  [8,   16,  32, 64, 128, 256, 512]\nbatch_sizes = [len(test_data)]*7\n\n\ntest_batch_stream = trax.data.BucketByLength(\n    boundaries, batch_sizes,\n    length_keys=[0, 1]  # As before: count inputs and targets to length.\n)(gnerator_data(test_data,test_label))\n\ntrain_batch_stream = trax.data.AddLossWeights(id_to_mask=vocab_word['<pad>'])(test_batch_stream)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T20:54:32.384610Z","iopub.execute_input":"2023-05-05T20:54:32.385075Z","iopub.status.idle":"2023-05-05T20:54:32.392357Z","shell.execute_reply.started":"2023-05-05T20:54:32.385036Z","shell.execute_reply":"2023-05-05T20:54:32.390844Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"code","source":"X,Y,M=next(train_batch_stream)\nX.shape,Y.shape,M.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-05T20:54:34.336509Z","iopub.execute_input":"2023-05-05T20:54:34.337255Z","iopub.status.idle":"2023-05-05T20:55:03.377530Z","shell.execute_reply.started":"2023-05-05T20:54:34.337214Z","shell.execute_reply":"2023-05-05T20:55:03.376648Z"},"trusted":true},"execution_count":217,"outputs":[{"execution_count":217,"output_type":"execute_result","data":{"text/plain":"((4796, 32), (4796, 32), (4796, 32))"},"metadata":{}}]},{"cell_type":"code","source":"def compute_accuracy(model,X,Y,M):\n    prediction=model.eval_model(X)\n    \n    numerator=np.argmax(prediction,axis=-1)\n    \n    comprasion=np.sum(numerator==Y)\n    \n    denominator=np.sum(M)\n    \n    accuracy=comprasion/denominator\n    return accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T21:04:06.834463Z","iopub.execute_input":"2023-05-05T21:04:06.834843Z","iopub.status.idle":"2023-05-05T21:04:06.842039Z","shell.execute_reply.started":"2023-05-05T21:04:06.834811Z","shell.execute_reply":"2023-05-05T21:04:06.840874Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"code","source":"print(f'Accuracy of Model is : {compute_accuracy(training,X,Y,M)}')","metadata":{"execution":{"iopub.status.busy":"2023-05-05T21:04:07.166169Z","iopub.execute_input":"2023-05-05T21:04:07.166534Z","iopub.status.idle":"2023-05-05T21:04:26.904738Z","shell.execute_reply.started":"2023-05-05T21:04:07.166503Z","shell.execute_reply":"2023-05-05T21:04:26.903975Z"},"trusted":true},"execution_count":232,"outputs":[{"name":"stdout","text":"Accuracy of Model is : 0.9617193341255188\n","output_type":"stream"}]},{"cell_type":"code","source":"def pred(sentence,tokenize_sentence=tokenize_sentence):\n    output=''\n    tokenize_sentence=tokenize_sentence(sentence,vocab_word)\n    tokenize_sentence=np.array(tokenize_sentence)\n    tokenize_sentence=np.expand_dims(tokenize_sentence,axis=0)\n    prediction=training.eval_model(tokenize_sentence)\n    prediction=np.argmax(prediction,axis=-1)[0]\n    for i in prediction:\n        tag=number_to_tags[int(i)]\n        output+=tag+' '\n    return output\n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T21:20:49.950634Z","iopub.execute_input":"2023-05-05T21:20:49.951049Z","iopub.status.idle":"2023-05-05T21:20:49.957516Z","shell.execute_reply.started":"2023-05-05T21:20:49.951013Z","shell.execute_reply":"2023-05-05T21:20:49.956765Z"},"trusted":true},"execution_count":312,"outputs":[]},{"cell_type":"code","source":"print(f'display actual output {tag[0]}')\nprint(f'display predicted output {pred(sentence[0])}')","metadata":{"execution":{"iopub.status.busy":"2023-05-05T21:23:59.278478Z","iopub.execute_input":"2023-05-05T21:23:59.278912Z","iopub.status.idle":"2023-05-05T21:23:59.740705Z","shell.execute_reply.started":"2023-05-05T21:23:59.278878Z","shell.execute_reply":"2023-05-05T21:23:59.739529Z"},"trusted":true},"execution_count":324,"outputs":[{"name":"stdout","text":"display actual output  O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\ndisplay predicted output O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}